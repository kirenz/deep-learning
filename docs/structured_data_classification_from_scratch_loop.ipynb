{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iNtJdvrb_vd"
      },
      "source": [
        "# Structured data classification\n",
        "\n",
        "This tutorial is mainly based on the Keras tutorial [\"Structured data classification from scratch\"](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) by Fran√ßois Chollet and [\"Classify structured data using Keras preprocessing layers\"](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers) by TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAbd3kbsb_vj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aubhVbfWb_vk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.7.1'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzNNij6qb_vl"
      },
      "source": [
        "## Data\n",
        "\n",
        "\n",
        "Here's the description of each feature:\n",
        "\n",
        "Column| Description| Feature Type\n",
        "------------|--------------------|----------------------\n",
        "Age | Age in years | Numerical\n",
        "Sex | (1 = male; 0 = female) | Categorical\n",
        "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
        "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
        "Chol | Serum cholesterol in mg/dl | Numerical\n",
        "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
        "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
        "Thalach | Maximum heart rate achieved | Numerical\n",
        "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
        "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
        "Slope | Slope of the peak exercise ST segment | Numerical\n",
        "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
        "Thal | normal; fixed defect; reversible defect | Categorical (string)\n",
        "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target\n",
        "\n",
        "### Data import\n",
        "Let's download the data and load it into a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EId7MS20b_vm"
      },
      "outputs": [],
      "source": [
        "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
        "df = pd.read_csv(file_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zW3GlXdWb_vo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>reversible</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
              "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
              "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
              "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
              "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
              "\n",
              "   ca        thal  target  \n",
              "0   0       fixed       0  \n",
              "1   3      normal       1  \n",
              "2   2  reversible       0  \n",
              "3   0      normal       0  \n",
              "4   0      normal       0  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following feature are continuous numerical features:\n",
        "\n",
        "- `age`\n",
        "- `trestbps`\n",
        "- `chol`\n",
        "- `thalach`\n",
        "- `oldpeak`\n",
        "- `slope`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following features are *categorical features* encoded as integers:\n",
        "\n",
        "- `sex`\n",
        "- `cp`\n",
        "- `fbs`\n",
        "- `restecg`\n",
        "- `exang`\n",
        "- `ca`\n",
        "\n",
        "The following feature is a *categorical features* encoded as string:\n",
        "\n",
        "- `thal`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Define outcome variable as y_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_label = 'target'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Correct data format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to string\n",
        "df['thal'] = df['thal'].astype(\"string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to categorical\n",
        "cat_convert = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'ca']\n",
        "\n",
        "for i in cat_convert:\n",
        "    df[i] = df[i].astype(\"category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Make lists of feature variables (without our label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make list of all numerical data (except label)\n",
        "list_num = df.drop(columns=[y_label]).select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Make list of all categorical data (except label)\n",
        "list_cat = df.drop(columns=[y_label]).select_dtypes(include=['category']).columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data splitting\n",
        "\n",
        "Let's split the data into a training and validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OFSnqGOPb_vp"
      },
      "outputs": [],
      "source": [
        "df_val = df.sample(frac=0.2, random_state=1337)\n",
        "df_train = df.drop(df_val.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 242 samples for training and 61 for validation\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(df_train), len(df_val))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transform to Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4a8d8ab_vq"
      },
      "source": [
        "- Let's generate [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) objects for our training and validation dataframes\n",
        "- The utility function converts each training and validation set into a tf.data.Dataset, then shuffles and batches the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "NXclBW3Cb_vq"
      },
      "outputs": [],
      "source": [
        "# Define a function to create our tensors\n",
        "\n",
        "def dataframe_to_dataset(dataframe, batch_size=32):\n",
        "    df = dataframe.copy()\n",
        "    labels = df.pop(y_label)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    df = ds.prefetch(batch_size)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use function\n",
        "train_ds = dataframe_to_dataset(train_dataframe)\n",
        "val_ds = dataframe_to_dataset(val_dataframe)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, use the newly created function (`dataframe_to_dataset`) to check the format of the data the input pipeline helper function returns by calling it on the training data, and use a small batch size to keep the output readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "\n",
        "train_ds = dataframe_to_dataset(df_train, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Let's take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every feature: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
            "A batch of ages: tf.Tensor([45 41 39 65 69], shape=(5,), dtype=int64)\n",
            "A batch of targets: tf.Tensor([0 0 0 1 1], shape=(5,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of ages:', train_features['age'])\n",
        "print('A batch of targets:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As the output demonstrates, the training set returns a dictionary of column names (from the DataFrame) that map to column values from rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q5DVC0b_vr"
      },
      "source": [
        "- Let's batch the datasets (combine some of our samples). Here, we use a mini-batch size of 32:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccngwlq_b_vr"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(32)\n",
        "val_ds = val_ds.batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWVbzdlob_vs"
      },
      "source": [
        "## Feature preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "### Preprocessing functions\n",
        "\n",
        "- Below, we define utility functions to do the feature preprocessing operations:\n",
        "\n",
        "- For each numeric feature in the dataset, you will use a tf.keras.layers.Normalization layer to standardize the distribution of the data.\n",
        "\n",
        "- Define a new utility function that returns a layer which applies feature-wise normalization to numerical features using that Keras preprocessing layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPnUDwDwb_vs"
      },
      "outputs": [],
      "source": [
        "# Define numerical preprocessing function\n",
        "def get_normalization_layer(name, dataset):\n",
        "    # Create a Normalization layer for our feature\n",
        "    normalizer = layers.Normalization(axis=None)\n",
        "\n",
        "    # Prepare a dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "    # Learn the statistics of the data\n",
        "    normalizer.adapt(feature_ds)\n",
        "\n",
        "    # Normalize the input feature\n",
        "    return normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Categorical data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define categorical preprocessing function\n",
        "def encode_categorical_feature(feature, name, dataset, is_string):\n",
        "\n",
        "    lookup_class = layers.StringLookup if is_string else layers.IntegerLookup\n",
        "    # Create a lookup layer which will turn strings into integer indices\n",
        "    lookup = lookup_class(output_mode=\"binary\")\n",
        "\n",
        "    # Prepare a Dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
        "\n",
        "    # Learn the set of possible string values and assign them a fixed integer index\n",
        "    lookup.adapt(feature_ds)\n",
        "\n",
        "    # Turn the string input into integer indices\n",
        "    encoded_feature = lookup(feature)\n",
        "    return encoded_feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Next, test the new function by calling it on the total uploaded pet photo features to normalize 'PhotoAmt':\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "photo_count_col = train_features['PhotoAmt']\n",
        "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
        "layer(photo_count_col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define another new utility function that returns a layer which maps values from a vocabulary to integer indices and multi-hot encodes the features using the tf.keras.layers.StringLookup, tf.keras.layers.IntegerLookup, and tf.keras.CategoryEncoding preprocessing layers:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  \n",
        "  # Create a layer that turns strings into integer indices.\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  # Otherwise, create a layer that turns integer values into integer indices.\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Encode the integer indices.\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Test the `get_category_encoding_layer` function by calling it on pet 'sex' feature to turn them into multi-hot encoded tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_type_col = train_features['Type']\n",
        "test_type_layer = get_category_encoding_layer(name='Type',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string')\n",
        "test_type_layer(test_type_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxgxJc1b_vt"
      },
      "source": [
        "With this done, we can create our preprocessing steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Normalize the numerical features and add them to one list of inputs called `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numerical features.\n",
        "for feature in list_num:\n",
        "  numeric_col = keras.Input(shape=(1,), name=feature)\n",
        "  normalization_layer = get_normalization_layer(feature, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs.append(numeric_col)\n",
        "  encoded_features.append(encoded_numeric_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Make a list of all encoded features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_features = layers.concatenate(encoded_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Note that we also could use a for loop to automate some of the steps above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can build the model: \n",
        "\n",
        "1. We use 32 number of units in the first layer\n",
        "1. We use [layers.Dropout()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) to prevent overvitting\n",
        "1. Our output layer has 1 output (since the classification task is binary)\n",
        "1. keras.Model groups layers into an object with training and inference features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First layer\n",
        "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
        "# Dropout to prevent overvitting\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Output layer\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Group all layers \n",
        "model = keras.Model(all_inputs, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", \n",
        "              loss =\"binary_crossentropy\", \n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzkR9bceb_vu"
      },
      "source": [
        "Let's visualize our connectivity graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtP52PWsb_vu"
      },
      "outputs": [],
      "source": [
        "# `rankdir='LR'` is to make the graph horizontal.\n",
        "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igsOv1jb_vv"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T15LQ3qNb_vv"
      },
      "outputs": [],
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUwMs6jb_vv"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV7e_9K2b_vw"
      },
      "outputs": [],
      "source": [
        "sample = {\n",
        "    \"age\": 60,\n",
        "    \"sex\": 1,\n",
        "    \"cp\": 1,\n",
        "    \"trestbps\": 145,\n",
        "    \"chol\": 233,\n",
        "    \"fbs\": 1,\n",
        "    \"restecg\": 2,\n",
        "    \"thalach\": 150,\n",
        "    \"exang\": 0,\n",
        "    \"oldpeak\": 2.3,\n",
        "    \"slope\": 3,\n",
        "    \"ca\": 0,\n",
        "    \"thal\": \"fixed\",\n",
        "}\n",
        "\n",
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
        "\n",
        "predictions = model.predict(input_dict)\n",
        "\n",
        "print(\n",
        "    \"This particular patient had a %.1f percent probability \"\n",
        "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "structured_data_classification_from_scratch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
