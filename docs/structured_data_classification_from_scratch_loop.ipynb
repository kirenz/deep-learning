{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iNtJdvrb_vd"
      },
      "source": [
        "# Structured data classification\n",
        "\n",
        "This tutorial is mainly based on the Keras tutorial [\"Structured data classification from scratch\"](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) by Fran√ßois Chollet and [\"Classify structured data using Keras preprocessing layers\"](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers) by TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAbd3kbsb_vj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "aubhVbfWb_vk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.7.1'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzNNij6qb_vl"
      },
      "source": [
        "## Data\n",
        "\n",
        "\n",
        "Here's the description of each feature:\n",
        "\n",
        "Column| Description| Feature Type\n",
        "------------|--------------------|----------------------\n",
        "Age | Age in years | Numerical\n",
        "Sex | (1 = male; 0 = female) | Categorical\n",
        "CP | Chest pain type (0, 1, 2, 3, 4) | Categorical\n",
        "Trestbpd | Resting blood pressure (in mm Hg on admission) | Numerical\n",
        "Chol | Serum cholesterol in mg/dl | Numerical\n",
        "FBS | fasting blood sugar in 120 mg/dl (1 = true; 0 = false) | Categorical\n",
        "RestECG | Resting electrocardiogram results (0, 1, 2) | Categorical\n",
        "Thalach | Maximum heart rate achieved | Numerical\n",
        "Exang | Exercise induced angina (1 = yes; 0 = no) | Categorical\n",
        "Oldpeak | ST depression induced by exercise relative to rest | Numerical\n",
        "Slope | Slope of the peak exercise ST segment | Numerical\n",
        "CA | Number of major vessels (0-3) colored by fluoroscopy | Both numerical & categorical\n",
        "Thal | normal; fixed defect; reversible defect | Categorical (string)\n",
        "Target | Diagnosis of heart disease (1 = true; 0 = false) | Target\n",
        "\n",
        "### Data import\n",
        "Let's download the data and load it into a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EId7MS20b_vm"
      },
      "outputs": [],
      "source": [
        "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
        "df = pd.read_csv(file_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zW3GlXdWb_vo"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>fixed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>reversible</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
              "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
              "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
              "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
              "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
              "\n",
              "   ca        thal  target  \n",
              "0   0       fixed       0  \n",
              "1   3      normal       1  \n",
              "2   2  reversible       0  \n",
              "3   0      normal       0  \n",
              "4   0      normal       0  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following feature are continuous numerical features:\n",
        "\n",
        "- `age`\n",
        "- `trestbps`\n",
        "- `chol`\n",
        "- `thalach`\n",
        "- `oldpeak`\n",
        "- `slope`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following features are *categorical features* encoded as integers:\n",
        "\n",
        "- `sex`\n",
        "- `cp`\n",
        "- `fbs`\n",
        "- `restecg`\n",
        "- `exang`\n",
        "- `ca`\n",
        "\n",
        "The following feature is a *categorical features* encoded as string:\n",
        "\n",
        "- `thal`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Define outcome variable as y_label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_label = 'target'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Correct data format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to string\n",
        "df['thal'] = df['thal'].astype(\"string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to categorical\n",
        "cat_convert = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'ca']\n",
        "\n",
        "for i in cat_convert:\n",
        "    df[i] = df[i].astype(\"category\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Make lists of feature variables (without our label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make list of all numerical data (except label)\n",
        "list_num = df.drop(columns=[y_label]).select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Make list of all categorical data (except label)\n",
        "list_cat = df.drop(columns=[y_label]).select_dtypes(include=['category']).columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data splitting\n",
        "\n",
        "Let's split the data into a training and validation set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OFSnqGOPb_vp"
      },
      "outputs": [],
      "source": [
        "df_val = df.sample(frac=0.2, random_state=1337)\n",
        "df_train = df.drop(df_val.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using 242 samples for training and 61 for validation\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(df_train), len(df_val))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transform to Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4a8d8ab_vq"
      },
      "source": [
        "- Let's generate [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) objects for our training and validation dataframes\n",
        "- The utility function converts each training and validation set into a tf.data.Dataset, then shuffles and batches the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "NXclBW3Cb_vq"
      },
      "outputs": [],
      "source": [
        "# Define a function to create our tensors\n",
        "\n",
        "def dataframe_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "    df = dataframe.copy()\n",
        "    labels = df.pop(y_label)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    df = ds.prefetch(batch_size)\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Now, use the newly created function (`dataframe_to_dataset`) to check the format of the data the input pipeline helper function returns by calling it on the training data, and use a small batch size to keep the output readable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 5\n",
        "\n",
        "train_ds = dataframe_to_dataset(df_train, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Let's take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Every feature: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
            "A batch of ages: tf.Tensor([45 41 39 65 69], shape=(5,), dtype=int64)\n",
            "A batch of targets: tf.Tensor([0 0 0 1 1], shape=(5,), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "[(train_features, label_batch)] = train_ds.take(1)\n",
        "\n",
        "print('Every feature:', list(train_features.keys()))\n",
        "print('A batch of ages:', train_features['age'])\n",
        "print('A batch of targets:', label_batch )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- As the output demonstrates, the training set returns a dictionary of column names (from the DataFrame) that map to column values from rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Q5DVC0b_vr"
      },
      "source": [
        "- Let's batch the datasets (combine some of our samples). Here, we use a mini-batch size of 32:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWVbzdlob_vs"
      },
      "source": [
        "## Feature preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Next, we define utility functions to do the feature preprocessing operations.\n",
        "\n",
        "In this tutorial, you will use the following preprocessing layers to demonstrate how to perform preprocessing, structured data encoding, and feature engineering:\n",
        "\n",
        "- tf.keras.layers.Normalization: Performs feature-wise normalization of input features.\n",
        "\n",
        "- tf.keras.layers.CategoryEncoding: Turns integer categorical features into one-hot, multi-hot, or tf-idf dense representations.\n",
        "\n",
        "- tf.keras.layers.StringLookup: Turns string categorical values into integer indices.\n",
        "\n",
        "- tf.keras.layers.IntegerLookup: Turns integer categorical values into integer indices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numerical preprocessing function\n",
        "\n",
        "- Define a new utility function that returns a layer which applies feature-wise normalization to numerical features using that Keras preprocessing layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "cPnUDwDwb_vs"
      },
      "outputs": [],
      "source": [
        "# Define numerical preprocessing function\n",
        "def get_normalization_layer(name, dataset):\n",
        "    \n",
        "    # Create a Normalization layer for our feature\n",
        "    normalizer = layers.Normalization(axis=None)\n",
        "\n",
        "    # Prepare a dataset that only yields our feature\n",
        "    feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "    # Learn the statistics of the data\n",
        "    normalizer.adapt(feature_ds)\n",
        "\n",
        "    # Normalize the input feature\n",
        "    return normalizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Next, test the new function by calling it on the total uploaded pet photo features to normalize 'PhotoAmt':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
              "array([-1.0903668, -1.542778 , -1.7689835,  1.1716888,  1.6241   ],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_age_feature = train_features['age']\n",
        "\n",
        "test_age_layer = get_normalization_layer('age', train_ds)\n",
        "\n",
        "test_age_layer(test_age_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical preprocessing functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Define another new utility function that returns a layer which maps values from a vocabulary to integer indices and multi-hot encodes the features using the tf.keras.layers.StringLookup, tf.keras.layers.IntegerLookup, and tf.keras.CategoryEncoding preprocessing layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
        "  \n",
        "  # Create a layer that turns strings into integer indices.\n",
        "  if dtype == 'string':\n",
        "    index = layers.StringLookup(max_tokens=max_tokens)\n",
        "  # Otherwise, create a layer that turns integer values into integer indices.\n",
        "  else:\n",
        "    index = layers.IntegerLookup(max_tokens=max_tokens)\n",
        "\n",
        "  # Prepare a `tf.data.Dataset` that only yields the feature.\n",
        "  feature_ds = dataset.map(lambda x, y: x[name])\n",
        "\n",
        "  # Learn the set of possible values and assign them a fixed integer index.\n",
        "  index.adapt(feature_ds)\n",
        "\n",
        "  # Encode the integer indices.\n",
        "  encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
        "\n",
        "  # Apply multi-hot encoding to the indices. The lambda function captures the\n",
        "  # layer, so you can use them, or include them in the Keras Functional model later.\n",
        "  return lambda feature: encoder(index(feature))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Test the get_category_encoding_layer function by calling it on pet 'Thal' features to turn them into multi-hot encoded tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_thal_feature = train_features['thal']\n",
        "\n",
        "test_thal_layer = get_category_encoding_layer(name='thal',\n",
        "                                              dataset=train_ds,\n",
        "                                              dtype='string')\n",
        "test_thal_layer(test_thal_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxgxJc1b_vt"
      },
      "source": [
        "Next, we will:\n",
        "\n",
        "- Apply the preprocessing utility functions defined earlier on our numerical and categorical features \n",
        "- Add all the feature inputs to a list."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Earlier, we used a small batch size to demonstrate the input pipeline. \n",
        "- Let's now create a new input pipeline with a larger batch size of 256:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "\n",
        "ds_train = dataframe_to_dataset(df_train, shuffle=True, batch_size=batch_size)\n",
        "ds_val = dataframe_to_dataset(df_val, shuffle=True, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Normalize the numerical features and add them to one list of inputs called `encoded_features`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_inputs = []\n",
        "encoded_features = []\n",
        "\n",
        "# Numerical features.\n",
        "for feature in list_num:\n",
        "  numeric_col = keras.Input(shape=(1,), name=feature)\n",
        "  normalization_layer = get_normalization_layer(feature, train_ds)\n",
        "  encoded_numeric_col = normalization_layer(numeric_col)\n",
        "  all_inputs.append(numeric_col)\n",
        "  encoded_features.append(encoded_numeric_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Make a list of all encoded features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_features = layers.concatenate(encoded_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Note that we also could use a for loop to automate some of the steps above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can build the model: \n",
        "\n",
        "1. We use 32 number of units in the first layer\n",
        "1. We use [layers.Dropout()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) to prevent overvitting\n",
        "1. Our output layer has 1 output (since the classification task is binary)\n",
        "1. keras.Model groups layers into an object with training and inference features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First layer\n",
        "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
        "# Dropout to prevent overvitting\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# Output layer\n",
        "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Group all layers \n",
        "model = keras.Model(all_inputs, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"adam\", \n",
        "              loss =\"binary_crossentropy\", \n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzkR9bceb_vu"
      },
      "source": [
        "Let's visualize our connectivity graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtP52PWsb_vu"
      },
      "outputs": [],
      "source": [
        "# `rankdir='LR'` is to make the graph horizontal.\n",
        "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5igsOv1jb_vv"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T15LQ3qNb_vv"
      },
      "outputs": [],
      "source": [
        "model.fit(train_ds, epochs=10, validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRUwMs6jb_vv"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV7e_9K2b_vw"
      },
      "outputs": [],
      "source": [
        "sample = {\n",
        "    \"age\": 60,\n",
        "    \"sex\": 1,\n",
        "    \"cp\": 1,\n",
        "    \"trestbps\": 145,\n",
        "    \"chol\": 233,\n",
        "    \"fbs\": 1,\n",
        "    \"restecg\": 2,\n",
        "    \"thalach\": 150,\n",
        "    \"exang\": 0,\n",
        "    \"oldpeak\": 2.3,\n",
        "    \"slope\": 3,\n",
        "    \"ca\": 0,\n",
        "    \"thal\": \"fixed\",\n",
        "}\n",
        "\n",
        "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
        "\n",
        "predictions = model.predict(input_dict)\n",
        "\n",
        "print(\n",
        "    \"This particular patient had a %.1f percent probability \"\n",
        "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "structured_data_classification_from_scratch",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
