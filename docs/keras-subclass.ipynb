{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQAstZ4o58n7"
      },
      "source": [
        "# Model subclass\n",
        "\n",
        "*This is a companion notebook for the excellent book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff) ([code provided by Fran√ßois Chollet](https://github.com/fchollet/deep-learning-with-python-notebooks)).* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNyxyNhn58n7"
      },
      "source": [
        "#### Rewriting our previous example as a subclassed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCVLwJQB58n7"
      },
      "source": [
        "**A simple subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4dn-U1cX58n7"
      },
      "outputs": [],
      "source": [
        "class CustomerTicketModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_departments):\n",
        "        super().__init__()\n",
        "        self.concat_layer = layers.Concatenate()\n",
        "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
        "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
        "        self.department_classifier = layers.Dense(\n",
        "            num_departments, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        title = inputs[\"title\"]\n",
        "        text_body = inputs[\"text_body\"]\n",
        "        tags = inputs[\"tags\"]\n",
        "\n",
        "        features = self.concat_layer([title, text_body, tags])\n",
        "        features = self.mixing_layer(features)\n",
        "        priority = self.priority_scorer(features)\n",
        "        department = self.department_classifier(features)\n",
        "        return priority, department"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JrdO3awX58n7"
      },
      "outputs": [],
      "source": [
        "model = CustomerTicketModel(num_departments=4)\n",
        "\n",
        "priority, department = model(\n",
        "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NARCA6Wu58n8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 1s 14ms/step - loss: 25.3773 - output_1_loss: 0.3349 - output_2_loss: 25.0425 - output_1_mean_absolute_error: 0.5011 - output_2_accuracy: 0.2352\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 36.3067 - output_1_loss: 0.3358 - output_2_loss: 35.9709 - output_1_mean_absolute_error: 0.5018 - output_2_accuracy: 0.0711\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
        "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
        "model.fit({\"title\": title_data,\n",
        "           \"text_body\": text_body_data,\n",
        "           \"tags\": tags_data},\n",
        "          [priority_data, department_data],\n",
        "          epochs=1)\n",
        "model.evaluate({\"title\": title_data,\n",
        "                \"text_body\": text_body_data,\n",
        "                \"tags\": tags_data},\n",
        "               [priority_data, department_data])\n",
        "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
        "                                                  \"text_body\": text_body_data,\n",
        "                                                  \"tags\": tags_data})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYmpi3jf58n8"
      },
      "source": [
        "#### Beware: What subclassed models don't support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqJLWRJu58n8"
      },
      "source": [
        "### Mixing and matching different components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTXkFxOu58n8"
      },
      "source": [
        "**Creating a Functional model that includes a subclassed model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mcLC86TH58n8"
      },
      "outputs": [],
      "source": [
        "class Classifier(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        if num_classes == 2:\n",
        "            num_units = 1\n",
        "            activation = \"sigmoid\"\n",
        "        else:\n",
        "            num_units = num_classes\n",
        "            activation = \"softmax\"\n",
        "        self.dense = layers.Dense(num_units, activation=activation)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "inputs = keras.Input(shape=(3,))\n",
        "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "outputs = Classifier(num_classes=10)(features)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NER1c3HR58n8"
      },
      "source": [
        "**Creating a subclassed model that includes a Functional model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "j5jL7D2P58n8"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(64,))\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
        "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=2):\n",
        "        super().__init__()\n",
        "        self.dense = layers.Dense(64, activation=\"relu\")\n",
        "        self.classifier = binary_classifier\n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.dense(inputs)\n",
        "        return self.classifier(features)\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8P4sKD858n8"
      },
      "source": [
        "### Remember: Use the right tool for the job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXgFZbmY58n9"
      },
      "source": [
        "## Using built-in training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYwutAhd58n9"
      },
      "source": [
        "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "lkeUkwPe58n9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2950 - accuracy: 0.9129 - val_loss: 0.1440 - val_accuracy: 0.9583\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1656 - accuracy: 0.9523 - val_loss: 0.1242 - val_accuracy: 0.9676\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1369 - accuracy: 0.9626 - val_loss: 0.1174 - val_accuracy: 0.9701\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1100 - accuracy: 0.9721\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "def get_mnist_model():\n",
        "    inputs = keras.Input(shape=(28 * 28,))\n",
        "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "    features = layers.Dropout(0.5)(features)\n",
        "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
        "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
        "train_images, val_images = images[10000:], images[:10000]\n",
        "train_labels, val_labels = labels[10000:], labels[:10000]\n",
        "\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-69jjA3K58n9"
      },
      "source": [
        "### Writing your own metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TSqFpZm58n9"
      },
      "source": [
        "**Implementing a custom metric by subclassing the `Metric` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "alQpxcI758n9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class RootMeanSquaredError(keras.metrics.Metric):\n",
        "\n",
        "    def __init__(self, name=\"rmse\", **kwargs):\n",
        "        super().__init__(name=name, **kwargs)\n",
        "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
        "        self.total_samples = self.add_weight(\n",
        "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
        "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "        self.mse_sum.assign_add(mse)\n",
        "        num_samples = tf.shape(y_pred)[0]\n",
        "        self.total_samples.assign_add(num_samples)\n",
        "\n",
        "    def result(self):\n",
        "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.mse_sum.assign(0.)\n",
        "        self.total_samples.assign(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yAidijh758n9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2944 - accuracy: 0.9128 - rmse: 7.1830 - val_loss: 0.1680 - val_accuracy: 0.9492 - val_rmse: 7.3523\n",
            "Epoch 2/3\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1637 - accuracy: 0.9538 - rmse: 7.3535 - val_loss: 0.1208 - val_accuracy: 0.9672 - val_rmse: 7.3989\n",
            "Epoch 3/3\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1376 - accuracy: 0.9629 - rmse: 7.3878 - val_loss: 0.1110 - val_accuracy: 0.9694 - val_rmse: 7.4185\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1135 - accuracy: 0.9701 - rmse: 7.4333\n"
          ]
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels))\n",
        "test_metrics = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBdLi6OH58n-"
      },
      "source": [
        "### Using callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zwhy9lb58n-"
      },
      "source": [
        "#### The EarlyStopping and ModelCheckpoint callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMPzQej_58n-"
      },
      "source": [
        "**Using the `callbacks` argument in the `fit()` method**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0gG1OpR158n-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2928 - accuracy: 0.9133 - val_loss: 0.1478 - val_accuracy: 0.9574\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1672 - accuracy: 0.9529 - val_loss: 0.1180 - val_accuracy: 0.9663\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1406 - accuracy: 0.9624 - val_loss: 0.1176 - val_accuracy: 0.9693\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1245 - accuracy: 0.9679 - val_loss: 0.1175 - val_accuracy: 0.9717\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.1164 - accuracy: 0.9713 - val_loss: 0.1073 - val_accuracy: 0.9755\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1089 - accuracy: 0.9735 - val_loss: 0.1145 - val_accuracy: 0.9741\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1054 - accuracy: 0.9750 - val_loss: 0.1143 - val_accuracy: 0.9753\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb351a68460>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        patience=2,\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"checkpoint_path.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uNspapXT58n-"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"checkpoint_path.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiON7y8T58n-"
      },
      "source": [
        "### Writing your own callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-nhiqLp58n-"
      },
      "source": [
        "**Creating a custom callback by subclassing the `Callback` class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "se9r1M0158n-"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.per_batch_losses = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        plt.clf()\n",
        "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
        "                 label=\"Training loss for each batch\")\n",
        "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
        "        self.per_batch_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "xdMydpBE58n_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.2937 - accuracy: 0.9127 - val_loss: 0.1441 - val_accuracy: 0.9600\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1636 - accuracy: 0.9538 - val_loss: 0.1332 - val_accuracy: 0.9642\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1379 - accuracy: 0.9627 - val_loss: 0.1149 - val_accuracy: 0.9709\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1247 - accuracy: 0.9671 - val_loss: 0.1013 - val_accuracy: 0.9759\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1161 - accuracy: 0.9710 - val_loss: 0.1080 - val_accuracy: 0.9749\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1108 - accuracy: 0.9734 - val_loss: 0.1096 - val_accuracy: 0.9775\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1040 - accuracy: 0.9755 - val_loss: 0.1143 - val_accuracy: 0.9760\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1023 - accuracy: 0.9764 - val_loss: 0.1058 - val_accuracy: 0.9781\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0939 - accuracy: 0.9783 - val_loss: 0.1260 - val_accuracy: 0.9767\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0935 - accuracy: 0.9786 - val_loss: 0.1126 - val_accuracy: 0.9783\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb351b6fa30>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=10,\n",
        "          callbacks=[LossHistory()],\n",
        "          validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U36YdKHE58n_"
      },
      "source": [
        "### Monitoring and visualization with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "MdsCAeZj58n_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-31 14:41:28.457683: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at summary_kernels.cc:65 : PERMISSION_DENIED: /train; Read-only file system\n"
          ]
        },
        {
          "ename": "PermissionDeniedError",
          "evalue": "/train; Read-only file system [Op:CreateSummaryFileWriter]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionDeniedError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/sl/9n0p_v712g9ftpzq9r9c254w0000gn/T/ipykernel_21187/4035301753.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m model.fit(train_images, train_labels,\n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDeniedError\u001b[0m: /train; Read-only file system [Op:CreateSummaryFileWriter]"
          ]
        }
      ],
      "source": [
        "model = get_mnist_model()\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(\n",
        "    log_dir=\"/full_path_to_your_log_dir\",\n",
        ")\n",
        "model.fit(train_images, train_labels,\n",
        "          epochs=3,\n",
        "          validation_data=(val_images, val_labels),\n",
        "          callbacks=[tensorboard])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb0oXGUc58n_"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /full_path_to_your_log_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2bbEs0-58n_"
      },
      "source": [
        "## Writing your own training and evaluation loops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmrGK_Qi58n_"
      },
      "source": [
        "### Training versus inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg7US5fA58n_"
      },
      "source": [
        "### Low-level usage of metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bv9FRZ358n_"
      },
      "outputs": [],
      "source": [
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "targets = [0, 1, 2]\n",
        "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "metric.update_state(targets, predictions)\n",
        "current_result = metric.result()\n",
        "print(f\"result: {current_result:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uZu4-0158n_"
      },
      "outputs": [],
      "source": [
        "values = [0, 1, 2, 3, 4]\n",
        "mean_tracker = keras.metrics.Mean()\n",
        "for value in values:\n",
        "    mean_tracker.update_state(value)\n",
        "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7zIL4gb58oA"
      },
      "source": [
        "### A complete training and evaluation loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UY95zEN58oA"
      },
      "source": [
        "**Writing a step-by-step training loop: the training step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsnBWTJ658oA"
      },
      "outputs": [],
      "source": [
        "model = get_mnist_model()\n",
        "\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = keras.optimizers.RMSprop()\n",
        "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
        "loss_tracking_metric = keras.metrics.Mean()\n",
        "\n",
        "def train_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs, training=True)\n",
        "        loss = loss_fn(targets, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"loss\"] = loss_tracking_metric.result()\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzKDnbE558oA"
      },
      "source": [
        "**Writing a step-by-step training loop: resetting the metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckdk6lkf58oA"
      },
      "outputs": [],
      "source": [
        "def reset_metrics():\n",
        "    for metric in metrics:\n",
        "        metric.reset_state()\n",
        "    loss_tracking_metric.reset_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7mhyG5A58oA"
      },
      "source": [
        "**Writing a step-by-step training loop: the loop itself**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmXJthuX58oA"
      },
      "outputs": [],
      "source": [
        "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "training_dataset = training_dataset.batch(32)\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    reset_metrics()\n",
        "    for inputs_batch, targets_batch in training_dataset:\n",
        "        logs = train_step(inputs_batch, targets_batch)\n",
        "    print(f\"Results at the end of epoch {epoch}\")\n",
        "    for key, value in logs.items():\n",
        "        print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkai0KJt58oA"
      },
      "source": [
        "**Writing a step-by-step evaluation loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEQHvbed58oB"
      },
      "outputs": [],
      "source": [
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8Y4Do6c58oB"
      },
      "source": [
        "### Make it fast with tf.function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juwn9uNb58oB"
      },
      "source": [
        "**Adding a `tf.function` decorator to our evaluation-step function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dm-YZ0058oB"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test_step(inputs, targets):\n",
        "    predictions = model(inputs, training=False)\n",
        "    loss = loss_fn(targets, predictions)\n",
        "\n",
        "    logs = {}\n",
        "    for metric in metrics:\n",
        "        metric.update_state(targets, predictions)\n",
        "        logs[\"val_\" + metric.name] = metric.result()\n",
        "\n",
        "    loss_tracking_metric.update_state(loss)\n",
        "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
        "    return logs\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_dataset = val_dataset.batch(32)\n",
        "reset_metrics()\n",
        "for inputs_batch, targets_batch in val_dataset:\n",
        "    logs = test_step(inputs_batch, targets_batch)\n",
        "print(\"Evaluation results:\")\n",
        "for key, value in logs.items():\n",
        "    print(f\"...{key}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frPzcqIv58oB"
      },
      "source": [
        "### Leveraging fit() with a custom training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wJIk-wb58oB"
      },
      "source": [
        "**Implementing a custom training step to use with `fit()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUQJZ6Oc58oB"
      },
      "outputs": [],
      "source": [
        "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
        "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = loss_fn(targets, predictions)\n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "\n",
        "        loss_tracker.update_state(loss)\n",
        "        return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [loss_tracker]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHE5xaUs58oB"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop())\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pV_VMk-Q58oC"
      },
      "outputs": [],
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, predictions)\n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "        self.compiled_metrics.update_state(targets, predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQA_egSb58oC"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(28 * 28,))\n",
        "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
        "features = layers.Dropout(0.5)(features)\n",
        "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.fit(train_images, train_labels, epochs=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esmyW5J-58oC"
      },
      "source": [
        "## Summary"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chapter07_working-with-keras.i",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
