{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST with TensorFlow\n",
        "\n",
        "*The following code example is mainly based on Mikhail Klassen's article [Tensorflow vs. PyTorch by example](https://towardsdatascience.com/tensorflow-vs-pytorch-by-example-66d37901c663)*\n",
        "\n",
        "## MNIST\n",
        "\n",
        "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.\n",
        "\n",
        "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
        "\n",
        "Image source: [Wikipedia, Josef Steppan](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0bxC_CUcGzk",
        "outputId": "d143fe3a-a989-4da5-cff4-42fa60ccd330"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sV3gUT4lK4uO"
      },
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "tf.keras.utils.set_random_seed(seed)\n",
        "\n",
        "# Save the model at the end?\n",
        "save_model = False\n",
        "\n",
        "# Batch sizes for training and testing\n",
        "batch_size = 64\n",
        "test_batch_size = 14\n",
        "\n",
        "# Training epochs (usually 10 is a good value)\n",
        "n_epochs = 2\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 1.0\n",
        "\n",
        "# Decay rate for adjusting the learning rate\n",
        "gamma = 0.7\n",
        "\n",
        "# Number of target classes in the MNIST data\n",
        "num_classes = 10\n",
        "\n",
        "# Data input shape\n",
        "input_shape = (28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki3C27nDdb53",
        "outputId": "0b54a525-98f2-444b-9e7f-b6b3da22a157"
      },
      "outputs": [],
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# The scaled mean and standard deviation of the MNIST dataset (precalculated)\n",
        "data_mean = 0.1307\n",
        "data_std = 0.3081\n",
        "\n",
        "# Reshape the input data\n",
        "x_train = x_train.reshape(x_train.shape[0], \n",
        "                          x_train.shape[1], \n",
        "                          x_train.shape[2], 1)\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], \n",
        "                        x_test.shape[1], \n",
        "                        x_test.shape[2], 1)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = (x_train/255.0 - data_mean) / data_std\n",
        "x_test = (x_test/255.0 - data_mean) / data_std\n",
        "\n",
        "# Convert labels to one-hot vectors\n",
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=num_classes)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tILjrHRFdb3x"
      },
      "outputs": [],
      "source": [
        "# Define the architecture of the neural network\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), strides=(1,1),\n",
        "                                      padding='valid', \n",
        "                                      activation='relu',\n",
        "                                      input_shape=input_shape),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), strides=(1,1),\n",
        "                                      padding='valid',\n",
        "                                      activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERKGNdfxdb1s",
        "outputId": "ef8fbf8d-bca9-44d5-89c4-502e408b5b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Decay the learning rate at a base rate of gamma roughly every epoch, which\n",
        "# is len(x_train) steps\n",
        "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    learning_rate,\n",
        "    decay_steps=len(x_train),\n",
        "    decay_rate=gamma)\n",
        "\n",
        "# Define the optimizer to user for gradient descent\n",
        "optimizer = tf.keras.optimizers.Adadelta(scheduler)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Display a model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PGJ8FXmMucW",
        "outputId": "7702889e-720e-41d0-d7e4-d2fd5e36b59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 141s 149ms/step - loss: 0.1881 - acc: 0.9423 - val_loss: 0.0512 - val_acc: 0.9826\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 136s 145ms/step - loss: 0.0704 - acc: 0.9794 - val_loss: 0.0384 - val_acc: 0.9881\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe1dff04940>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=n_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          validation_batch_size=test_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PomeYxKcdbzo"
      },
      "outputs": [],
      "source": [
        "if save_model:\n",
        "    model.save_weights(\"mnist_cnn_tf.ckpt\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST - Tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
